# -*- coding: utf-8 -*-
"""parse_data.ipynb

Automatically generated by Colaboratory.

"""

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/My Drive/Colab Notebooks/GraphNN'

import pandas as pd
import numpy as np

import stellargraph as sg
from stellargraph.mapper import PaddedGraphGenerator
from stellargraph.layer import GCNSupervisedGraphClassification
from stellargraph import StellarGraph

from stellargraph import datasets

from sklearn import model_selection
from IPython.display import display, HTML

from tensorflow.keras import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense
from tensorflow.keras.losses import binary_crossentropy
from tensorflow.keras.callbacks import EarlyStopping
import tensorflow as tf
import matplotlib.pyplot as plt
import pickle

graphs, skeleton_features = pickle.load(open('all_graphs.pkl', 'rb'))
summary = pd.DataFrame(
    [(g.number_of_nodes(), g.number_of_edges()) for g in graphs],
    columns=["nodes", "edges"],
)
summary.describe().round(1)

generator = PaddedGraphGenerator(graphs=graphs)

"""
train_subjects, test_subjects = model_selection.train_test_split(
    graph_subjects, train_size=140, test_size=None, stratify=graph_subjects
)
val_subjects, test_subjects = model_selection.train_test_split(
    graph_subjects, train_size=500, test_size=None, stratify=graph_subjects
)
"""

def create_graph_classification_model(generator, drop_out, layersizes, adam):
    gc_model = GCNSupervisedGraphClassification(
        layer_sizes=layersizes,
        activations=["relu", "relu"],
        generator=generator,
        dropout=drop_out,
    )
    x_inp, x_out = gc_model.in_out_tensors()
    """for i in range(num_layers//2):
        
        predictions = Dense(units=num_layers//2)(x_out)"""
        
    predictions = Dense(units=16)(x_out)
    predictions = Dense(units=8)(predictions)
    predictions = Dense(units=1)(predictions)

    # Let's create the Keras model and prepare it for training
    model = Model(inputs=x_inp, outputs=predictions)
    model.compile(optimizer=Adam(adam), loss=binary_crossentropy, metrics=["acc"])

    return model

epochs = 50  
folds = 5  
n_repeats = 2

"""
es = EarlyStopping(
    monitor="val_loss", min_delta=0, patience=25, restore_best_weights=True
)
"""

def train_fold(model, train_gen, test_gen, es, epochs):
    history = model.fit(
        train_gen, epochs=epochs, validation_data=test_gen, verbose=0,
    )
    test_metrics = model.evaluate(test_gen, verbose=0)
    test_acc = test_metrics[model.metrics_names.index("acc")]

    return history, test_acc

def get_generators(train_index, test_index, graph_labels, batch_size):
    train_gen = generator.flow(
        train_index, targets=graph_labels.iloc[train_index].values, batch_size=batch_size
    )
    test_gen = generator.flow(
        test_index, targets=graph_labels.iloc[test_index].values, batch_size=batch_size
    )

    return train_gen, test_gen


stratified_folds = model_selection.RepeatedStratifiedKFold(
    n_splits=folds, n_repeats=n_repeats
).split(graph_labels, graph_labels)

for i, (train_index, test_index) in enumerate(stratified_folds):
    print(i)
    train_gen, test_gen = get_generators(
        train_index, test_index, graph_labels, batch_size=20
    )

    model = create_graph_classification_model(generator)

    history, acc = train_fold(model, train_gen, test_gen, es, epochs)

    test_accs.append(acc)

print(np.mean(test_accs))
print(np.std(test_accs))