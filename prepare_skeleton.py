# -*- coding: utf-8 -*-
"""parse_data.ipynb

Automatically generated by Colaboratory.

"""

# Commented out IPython magic to ensure Python compatibility.
# %cd '/content/drive/My Drive/Colab Notebooks/GraphNN'


# Tengyu's code.
import os
bbox_dir = os.path.join('OBB')
bbox_dict = {}
for d in os.listdir(bbox_dir):
    if '.' in d or '_' in d:
        continue
    for f in os.listdir(os.path.join(bbox_dir, d)):
        if len(f) > 12:
            continue
        bboxes = pickle.load(open(os.path.join(bbox_dir, d, f), 'rb'))[0]
        bbox_dict[f[:-4]] = bboxes
        
#!pip install trimesh
#!pip install pyquaternion

# Get skeletons.
import os
import numpy as np
from pyquaternion.quaternion import Quaternion as Q
import pickle
import torch
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

import kinematics as K
from visualization import draw_obj

all_skeletons = []
all_obj_configs = []
all_obj_cat = []
for i_data, data_dict in enumerate(hoi_data):
    if i_data in [65, 67, 78, 97, 103, 131, 144, 149, 150, 151, 152, 153, 160, 173, 177, 178]:   # incorrect sitting
        continue
    if i_data in [14, 68, 69, 70, 71, 129, 130, 131, 136, 137, 138, 139, 140, 141, 169]:   # incorrect labeling -> incorrect relationship 130? 169?
        continue
    #print('\r%d/%d'%(i_data, total), end='')
    
    print(i_data)
    print(data_dict)
    # extract obj bboxes
    obj = data_dict['object']
    if obj['hash'] not in bbox_dict:
        continue
    # extract skeleton
    skeleton = data_dict['person']['skeleton']
    print(skeleton)
    print(len(skeleton))
    skeleton = np.array([skeleton[x] for x in K.joint_names]).astype(np.float32)
    center = np.array(data_dict['person']['root_position']).astype(np.float32)
    skeleton -= center
    #print(skeleton)
    print(len(skeleton))
    rotation = np.array(data_dict['person']['root_rotation']).astype(np.float32)[[3,0,1,2]]
    skeleton = np.matmul(Q(rotation).inverse.rotation_matrix, skeleton.T).T
    #print(skeleton)
    print(len(skeleton))
    obj_config = []
    obj_cat_id = []
    for part_id in bbox_dict[obj['hash']]:
        print(part_id)
        for bbox in bbox_dict[obj['hash']][part_id]:
            print(bbox)
            if bbox is None:
                continue
            T1,T2,T3,D,W,H,R = bbox
            R2 = Q(rotation).inverse * Q(np.array(obj['root_rotation'])[[3,0,1,2]])
            dx, dy, dz = (float(x) for x in obj['root_position'])
            dx -= center[0]
            dy -= center[1]
            dz -= center[2]
            obj_config.append([T3,T2,T1,D,W,H,*R.rotation_matrix[:,:2].reshape([6]),dx,dy,dz,*R2.rotation_matrix[:,:2].reshape([6])])
            obj_cat_id.append(part_id)

    all_skeletons.append(skeleton)
    all_obj_configs.append(obj_config)
    all_obj_cat.append(obj_cat_id)
    
# Get unique chair trees.   
all_chair = []
chair_folder = '/content/drive/My Drive/Colab Notebooks/GraphNN/OBB/Chair'
import os
for d in os.listdir(chair_folder):
  all_chair.append(d[:-4])
  
annotations_folder = '/content/drive/My Drive/Colab Notebooks/GraphNN/annotations'
folders = []
models = []
model_folder = []
for d in os.listdir(annotations_folder):
  for x in os.listdir('/content/drive/My Drive/Colab Notebooks/GraphNN/annotations/{}'.format(d)):
    current_dir = '/content/drive/My Drive/Colab Notebooks/GraphNN/annotations/{}'.format(d)
    if (x == "meta.json"):
      current_file = '{}/meta.json'.format(current_dir)
      with open(current_file) as to_parse:
        json_output = json.load(to_parse)
        model = json_output['model_id']
        if (model in all_chair):
          models.append(model)
          folders.append(d)
          model_folder.append([model,d])
          
json_to_parse = []
obj_ids = []  # object hash
for d in os.listdir(annotations_folder):
  if (d not in folders):
    continue
  else:
    for x in os.listdir('/content/drive/My Drive/Colab Notebooks/GraphNN/annotations/{}'.format(d)):
      current_dir = '/content/drive/My Drive/Colab Notebooks/GraphNN/annotations/{}'.format(d)
      if (x == "result.json"):
        current_file = '{}/result.json'.format(current_dir)
        with open(current_file) as to_parse:
          json_output = json.load(to_parse)
          json_to_parse.append(json_output)
          obj_id = model_folder.find(d)
          current_obj = obj_id[0]
          obj_ids.append(current_obj)
          
# Parse every chair file.
import parser
output_parsed = []
json_marker = []
for i in range(len(json_to_parse)):
  parser.parse_chair(json_to_parse[i])
  output_parsed.append(parser)
  json_marker.append(obj_ids[i])
  
print(output_parsed)

# Create association between person and object.
index = 0
hashes = []
hashx = []
association = {} # object: list of persons
for sit in sit_data:
  person = sit['object']
  hash1 = person['hash']
  if (hash1 in all_chair):
    hashx.append(hash1)
    hashes.append(index)
    if hash1 not in association:
        association[hash1] = index
        
    else:
        assocation[hash1].append(index)
        
  index = index + 1
  
# Add as features to leaf nodes.
# len(output_parsed) = 121

# dim_21 = 21 or 3-dim array. indices = corresponding nodes.

updated_parsed = []
root_features = None
for i in range(len(output_parsed)):
  dim_21 = []
  indices = []
  current_cat = all_obj_cat[i]
  current_skeleton = all_skeletons[i]
  current_config = all_obj_configs[i]
  
  # add leaf nodes 
  for i in range(len(current_config)):
    # if in source
    if (current_cat[i] in output_parsed[i][1]):
      dim_21.append(current_cat[i])
      indices.append(output_parsed[i][1]))
      
  # add root node feature
  #dim_21.append(current_skeleton)
  root_features = current_skeleton
  #indices.append("Sitting Furniture")
  
import pandas as pd  

# Convert to pandas data frame and save to pkl.

# as root
square_edges = pd.DataFrame(
    {"source": parsed_chair[0][0], "target": parsed_chair[0][1]}
)

square_node_data = pd.DataFrame(
    {"attributes": dim_21}, index=indices
)

frames = [square_edges, square_node_data]
result = pd.concat(frames)

result.to_pickle("./{}/pkl".format(obj_id_))

square_edges = pd.DataFrame(
    {"source": parsed_chair[0][0], "target": parsed_chair[0][1]}
)

square_node_data = pd.DataFrame(
    {"attributes": dim_21}, index=indices
)

frames = [square_edges, square_node_data]
result = pd.concat(frames)

with open("./{}.pkl".format(obj_id), 'w') as f: 
    pickle.dump(frames, root_features)